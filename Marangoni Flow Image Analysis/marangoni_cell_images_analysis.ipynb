{"cells":[{"cell_type":"markdown","metadata":{"id":"EVJyUWtfVIys"},"source":["## Image Analysis of Marangoni Cell via YOLOv4 tiny  \n","### - 지구과학교육과 16학번 한동환(handh21@snu.ac.kr)\n","\n","\n","1. Install Darknet\n","\n","  Darknet이라 하는 YOLO 알고리즘의 중추적인 역할을 하는 프로그램이 담긴 파일 다운로드 받기 \n","2. Making Images Labels\n","\n","  YOLO 알고리즘에 학습 시키기 위해서는 이미지 내의 객체에 대한 정보가 필요하다.\n","  \n","  객체 종류 / 중심 x 위치 / 중심 y 위치 / 너비 / 높이\n","\n","  이를 labelImg-master라는 프로그램을 통해 쉽게 만들 수 있다.\n","\n","  자세한 설명은 하단 참조\n","\n","3. YOLO 알고리즘 설정하기\n","\n","4. Learning - iteration: 4000~10000\n","\n","  알고리즘 학습 단계\n","5. Prediction\n","\n","  학습한 알고리즘을 통해 이미지를 인식시켜보는 단계\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"pD4wp5O1b8KL"},"source":["### 1. Install Darknet\n","\n","Google colab에 YOLO v4 -tiny 버전을  설치하는 것을 기준으로 하였다.\n","\n","아래의 순서대로 차근차근 설치하면 된다.\n","\n","YOLO v3, v3-tiny, v4, v5와 같은 다른 버전도 설치 가능\n","\n","만약 GPU가 있는 서버를 이용한다면 Mobaxterm이나 Putty에서 이용 가능"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kHjP4X3yUXVB"},"outputs":[],"source":["%%capture\n","!git clone https://github.com/AlexeyAB/darknet.git\n","%cd darknet\n","import re\n","!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n","!sed -i 's/GPU=0/GPU=1/' Makefile\n","!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n","!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n","!make\n","!chmod +x ./darknet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":311,"status":"ok","timestamp":1654576978075,"user":{"displayName":"한동환","userId":"11772705162839800097"},"user_tz":-540},"id":"fecFnOpre3dO","outputId":"552f194b-596a-49ba-ae18-b706b4292e20"},"outputs":[{"name":"stdout","output_type":"stream","text":["TensorFlow 1.x selected.\n"]}],"source":["%tensorflow_version 1.x"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":2152,"status":"ok","timestamp":1654576982405,"user":{"displayName":"한동환","userId":"11772705162839800097"},"user_tz":-540},"id":"9d8jmxq1e6mc","outputId":"afca2f22-6868-42f7-bb92-96d1b7691b82"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'1.15.2'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import tensorflow as tf\n","tf.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iBr432Qre_mX"},"outputs":[],"source":["#utility function\n","## Google Colab 환경에서는 cv2.imshow 함수가 잘 작동하지 않아 이를 대체할 함수를 미리 만들어준다.\n","## Colab에서 실행시키는 것이 아니라 자체 서버에서 실행시키는 경우에는 생략가능하다. \n","\n","def imShow(path):\n","  import cv2\n","  import matplotlib.pyplot as plt\n","  %matplotlib inline\n","\n","  image = cv2.imread(path)\n","  height, width = image.shape[:2]\n","  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n","\n","  fig = plt.gcf()\n","  fig.set_size_inches(18, 10)\n","  plt.axis(\"off\")\n","  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8865,"status":"ok","timestamp":1654576996371,"user":{"displayName":"한동환","userId":"11772705162839800097"},"user_tz":-540},"id":"arcRj7XPfCN9","outputId":"fdced544-7a57-4799-8582-512c47c7d206"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n","Cloning into 'yolotinyv3_medmask_demo'...\n","remote: Enumerating objects: 1733, done.\u001b[K\n","remote: Total 1733 (delta 0), reused 0 (delta 0), pack-reused 1733\u001b[K\n","Receiving objects: 100% (1733/1733), 208.88 MiB | 34.13 MiB/s, done.\n","Resolving deltas: 100% (120/120), done.\n","Checking out files: 100% (1537/1537), done.\n","/content/yolotinyv3_medmask_demo\n"]}],"source":["repo_url = 'https://github.com/GotG/yolotinyv3_medmask_demo'\n","import os\n","%cd /content\n","repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n","!git clone {repo_url}\n","%cd {repo_dir_path}"]},{"cell_type":"markdown","source":["이 단계가 설치에서 매우 중요하다. YOLO 알고리즘을 이용해서 인식하고자하는 객체가 있을 것이다. 그것이 어떤 것인지 여기에 입력을 해주어야한다. 입력하는 순서에 따라 class의 number가 결정된다.\n","\n","가령, 이 알고리즘을 통해 이미지 속의 고양이, 강아지, 캥거루, 곰, 코알라를 구별하고자 한다면 아래에서\n","\n","labels = ['cat', 'dog', 'kangaroo', 'bear', 'koala'] 라 입력해야한다.\n","\n","이 경우, cat이 0번 클래스, dog이 1번 클래스, kangaroo가 2번 클래스, bear가 3번 클래스, koala가 4번 클래스가 된다."],"metadata":{"id":"_a_qrRsRnzuT"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":273,"status":"ok","timestamp":1654577034125,"user":{"displayName":"한동환","userId":"11772705162839800097"},"user_tz":-540},"id":"9pUGo6RuhxI_","outputId":"97a9f538-3b39-4075-909e-c8cf14162eef"},"outputs":[{"name":"stdout","output_type":"stream","text":["marangoni cell\n","scale bar\n","information"]}],"source":["###################################### Setting the Label #############################################\n","\n","labels_path = '/content/yolotinyv3_medmask_demo/obj.names'\n","\n","# 이 부분 반드시 수정하기!!! ================================================\n","labels = ['marangoni cell', 'scale bar', 'information']\n","# ===========================================================================\n","\n","with open(labels_path, 'w') as f:\n","\n","    f.write('\\n'.join(labels))\n","\n","#check that the labels file is correct\n","!cat /content/yolotinyv3_medmask_demo/obj.names"]},{"cell_type":"markdown","source":["YOLO 알고리즘을 학습시키기 위해서는 obj.data 파일에 크게 5개의 정보를 입력해주어야 한다.\n","\n","1. 총 몇 종류의 객체들을 인식할 것인지를 나타내는 classes 정보\n","\n","   (가령, 고양이, 강아지, 캥거루, 곰, 코알라인 경우에는 총 5개 종류의 객체를 인식하므로 classes = 5)\n","\n","2. 어떤 이미지들을 학습에 사용할 것인지 경로를 나타내는 train.txt파일\n","   \n","   (가령, \n","\n","  /content/drive/MyDrive/cbe_paper/data_augmt3/coarse_salt_15.jpg\n","/content/drive/MyDrive/cbe_paper/AgNW_30_001/AgNW_30_001.avi_000007099.jpg\n","/content/drive/MyDrive/cbe_paper/data_augmt3/log_contrast_15.jpg\n","\n","  와 같이 경로들이 나열되어 있는 텍스트 파일이 어느 위치에 있는지 입력해야한다.)\n","\n","  이러한 텍스트 파일을 어떻게 만드는지는 make_sets_txtfile 파일 참조.\n","\n","3. 어떤 이미지들을 테스트에 사용할 것인지 경로를 나타내는 valid.txt파일\n","\n","   (2.와 동일)\n","\n","4. 어떤 객체들을 인식할 것인지 그 이름들을 나열한 obj.names 파일\n","\n","5. iteration이 진행됨에 따라 weight 파일이 업데이트 될 텐데, 이러한 학습 기록을 어느 폴더에 저장할 것인지를 나타내는 backup 폴더경로\n","\n"],"metadata":{"id":"Ct_2MpCIpdAJ"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":332,"status":"ok","timestamp":1654577038189,"user":{"displayName":"한동환","userId":"11772705162839800097"},"user_tz":-540},"id":"P_ZaBIkrixJ9","outputId":"7fa1cde5-4e58-490f-cf27-4ab10aea2488"},"outputs":[{"name":"stdout","output_type":"stream","text":["classes= 3\n","train  = /content/yolotinyv3_medmask_demo/train.txt\n","valid  = /content/yolotinyv3_medmask_demo/valid.txt\n","names = /content/yolotinyv3_medmask_demo/obj.names\n","backup = backup/"]}],"source":["import re\n","objdata = '/content/yolotinyv3_medmask_demo/obj.data'\n","with open(objdata) as f:\n","    s = f.read()\n","\n","#the number of classes is equal to the number of labels\n","num_classes = len(labels)   \n","s = re.sub('classes= \\d*','classes= ' + str(num_classes),s)\n","\n","with open(objdata, 'w') as f:\n","  f.write(s)\n","!cat /content/yolotinyv3_medmask_demo/obj.data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1654577056942,"user":{"displayName":"한동환","userId":"11772705162839800097"},"user_tz":-540},"id":"_QkJ8y-asv9I","outputId":"44356e58-f8bc-41b9-9ab6-787cd3947f86"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/yolotinyv3_medmask_demo\n"]}],"source":["%cd ../yolotinyv3_medmask_demo/"]},{"cell_type":"markdown","source":["Google Colab에 그냥 저장시키면 런타임이 지나고 기록이 삭제되어버리므로 Google Drive에 저장하기 위해 파일을 옮긴다.\n","\n","자체 서버를 이용하여 진행하는 경우 이 단계 생략 가능"],"metadata":{"id":"JK9uj2hcyskI"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19495,"status":"ok","timestamp":1654577080069,"user":{"displayName":"한동환","userId":"11772705162839800097"},"user_tz":-540},"id":"G03Rybosuov5","outputId":"aa8204df-7149-4e2f-bef9-4a8b7cc36f4c"},"outputs":[{"name":"stdout","output_type":"stream","text":["shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n","mv: cannot overwrite non-directory '/content/drive/MyDrive/cbe_paper/darknet/darknet' with directory '/content/darknet'\n"]}],"source":["!mv /content/yolotinyv3_medmask_demo /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo\n","!mv /content/darknet /content/drive/MyDrive/cbe_paper/darknet"]},{"cell_type":"markdown","metadata":{"id":"ons905c_yT6a"},"source":["### 2. Making Image Label\n","\n","  YOLO 알고리즘에 학습 시키기 위해서는 이미지 내의 객체에 대한 정보가 필요하다.\n","  \n","  객체 종류 / 중심 x 위치 / 중심 y 위치 / 너비 / 높이\n","\n","  위와 같은 정보가 담겨 있는 텍스트 파일을 이미지 마다 하나씩 만들어야 한다.\n","\n","  가령, /desktop/dog_picture/dog1.jpg라는 이미지가 있다면, 그와 동일한 이름을 가진 /desktop/dog_picture/dog1.txt 파일을 만든 뒤에 위의 정보를 이 안에 입력해야하는 것이다.\n","\n","  이를 labelImg-master라는 프로그램을 이용하면 드레그를 통해 쉽게 만들 수 있다.\n","\n","\n","  프로그램 다운로드 방법은 https://github.com/tzutalin/labelImg#labelimg 에서 확인할 수 있다.\n","\n","파일 다운로드 후 커맨드 창에 labelImg.py라는 파일이 위치한 곳으로 경로를 설정한 뒤에 python labelImg.py라 입력하면 프로그램이 실행된다."]},{"cell_type":"markdown","source":["### 3. YOLO 알고리즘 설정하기"],"metadata":{"id":"BII39NEcnAAX"}},{"cell_type":"markdown","source":["YOLO 알고리즘과 관련한 여러 설정들은 yolov4-tiny.cfg라는 파일 내에서 조절이 가능하다. 아래를 보면 이 파일이 어떻게 구성되어 있는지 확인 가능하다. 이 파일을 수정함으로써 설정을 변경할 수 있다. mobaxterm이나 putty를 사용하는 경우에는 직접 파일에 들어가서 수정이 가능하다. Google Colab 내에서는 아래와 같은 방법으로 설정을 바꾸는 것이 가장 편리하다."],"metadata":{"id":"FW9LgGKNzqkD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"f2oHBovGyadi"},"outputs":[],"source":["!head -n 1000 /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/yolov4-tiny.cfg"]},{"cell_type":"markdown","source":["가장 먼저 수정해야할 것은 max_batch이다. 이 것은 알고리즘이 총 몇 iteration 동안 학습을 할 것인지를 나타낸다. 가령, 10000 iteration을 학습할 것이면 max_batch를 10000이라 설정해야한다. 일반적으로 calss의 갯수에 2000을 곱한 값까지는 최소한 학습 해주어야 한다고 알려져있다. 그렇다고 너무 숫자를 크게하면 오버피팅이 될 수 있으므로 학습 추이를 보며 적절할 때 학습을 끝내주어야 한다.\n","\n","또한, 두번째로 수정해야할 것은 num_filters이다. 이 값은 (class의 수 + 5) * 3이 되어야 한다. 그 이유는 YOLO 알고리즘이 객체의 width, height, x, y, confidence로 구성된 총 5가지 요소를 고려하고 각각의 grid cell마다 총 3개의 box를 detect하기 때문이다. 만약, Bounding Box를 기울어지게 설정하여 angle이라는 요소를 추가하게 된다면 width, height, x, y, confidence에 angle이 추가되므로 5가 아닌 6을 더해야할 것이다.\n","\n","맨 마지막으로는 GPU 사용 여부를 입력해야한다. 당연히 GPU가 있는 경우 아래와 같이 수정하면 된다. "],"metadata":{"id":"AJDcaBzq0S6A"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uejkwt4Hyaqh"},"outputs":[],"source":["import re\n","# set the number of max_batches - min 2000 per class:\n","max_batch= 10000\n","# calculate the 2 steps values:\n","step1 = 0.8 * max_batch\n","step2 = 0.9 * max_batch\n","#subdivisions define the minibatch size: minibatch = batch/subdivisions\n","#we set subdivisions to 4. if using larger resolutions, may have to increase\n","#the this number to 8 16 or even 32. default resolution is 416x416\n","subdivisions = 4\n","\n","\n","# we also need to adjust the number of classes and a parameter called filter size \n","# that are both is inside the model structure\n","\n","# num_classes = len(labels)\n","num_filters = (3 + 5) * 3\n","\n","cfg_file = '/content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/yolov4-tiny.cfg'\n","\n","with open(cfg_file) as f:\n","    s = f.read()\n","# (re.sub('[a-z]*@', 'ABC@', s))\n","s = re.sub('subdivisions=\\d*','subdivisions='+str(subdivisions),s)\n","s = re.sub('max_batches = \\d*','max_batches = '+str(max_batch),s)\n","s = re.sub('steps=\\d*,\\d*','steps='+\"{:.0f}\".format(step1)+','+\"{:.0f}\".format(step2),s)\n","s = re.sub('classes=\\d*','classes='+str(3),s)\n","s = re.sub('pad=1\\nfilters=\\d*','pad=1\\nfilters='+\"{:.0f}\".format(num_filters),s)\n","# pad=1\\nfilters=\\d\\d\n","s = re.sub('CUDNN=0','CUDNN=1',s)\n","s = re.sub('OPENCV=0','OPENCV=1',s)\n","\n","with open(cfg_file, 'w') as f:\n","  s = re.sub('GPU=0','GPU=1',s)\n","  f.write(s)"]},{"cell_type":"markdown","source":["###3. Training\n","\n","이제 알고리즘 학습을 위한 모든 준비가 끝났다. 아래와 같이 입력하면 학습이 가능하다. Iteration이 진행됨에 따라 weight파일이 업데이트 되게 되는데, weight 파일이 용량이 꽤 크기 때문에 매 iteration마다 backup 폴더에 저장하는 것은 비효율적이다. 그래서 기본 설정으로는 10000iteration마다 저장 되게 설정이 되어있다. \n","\n","만약 이를 100iteraton이나 1000iteration으로 바꾸고 싶다면 darknet 폴더를 들어가서 src 파일 내의 detector.c 내부의 설정을 바꾸고 !make를 커맨드 창에 입력해서 darknet을 다시 설치해주면 된다. "],"metadata":{"id":"khncPsn4puez"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"jBMKGPVnoXLo"},"outputs":[],"source":["!/content/darknet/darknet detector train /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/obj.data /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/yolov4-tiny.cfg /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/yolov4-tiny.conv.29 -dont_show -ext_output -map"]},{"cell_type":"markdown","source":["###4. Test\n","\n","학습된 알고리즘이 얼마나 testset을 잘 인식하는지를 map를 기준으로 확인이 가능하다. 몇 iteration일 때의 학습결과를 사용할 것인지 저장된 weight 파일을 지정하면 그 학습 기록을 토대로 알고리즘이 testset을 인식하고 그 결과를 바로 보여준다. "],"metadata":{"id":"fzSlopoJp-5l"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":949,"status":"ok","timestamp":1655048891810,"user":{"displayName":"한동환","userId":"11772705162839800097"},"user_tz":-540},"id":"GWSts7mNjIij","outputId":"583a2429-29cb-4fdf-d328-cc2de0cb298c"},"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: /content/darknet/darknet: No such file or directory\n"]}],"source":["!/content/darknet/darknet detector map /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/obj.data /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/yolov4-tiny.cfg \"/content/drive/MyDrive/cbe_paper/backup/yolov4-tiny_best.weights\" -points 0"]},{"cell_type":"code","source":["!/content/darknet/darknet detector map /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/obj.data /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/yolov4-tiny.cfg \"/content/drive/MyDrive/cbe_paper/backup/yolov4-tiny_1000.weights\" -points 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TMS2bEVTn-_v","executionInfo":{"status":"ok","timestamp":1654864662549,"user_tz":-540,"elapsed":9888,"user":{"displayName":"한동환","userId":"11772705162839800097"}},"outputId":"b4f309da-1c36-4e9f-a92d-9c6fdfd7e423"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" CUDA-version: 11010 (11020), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n"," CUDNN_HALF=1 \n"," OpenCV version: 3.2.0\n"," 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n","net.optimized_memory = 0 \n","mini_batch = 1, batch = 4, time_steps = 1, train = 0 \n","   layer   filters  size/strd(dil)      input                output\n","   0 Create CUDA-stream - 0 \n"," Create cudnn-handle 0 \n","conv     32       3 x 3/ 2    416 x 416 x   3 ->  208 x 208 x  32 0.075 BF\n","   1 conv     64       3 x 3/ 2    208 x 208 x  32 ->  104 x 104 x  64 0.399 BF\n","   2 conv     64       3 x 3/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.797 BF\n","   3 route  2 \t\t                       1/2 ->  104 x 104 x  32 \n","   4 conv     32       3 x 3/ 1    104 x 104 x  32 ->  104 x 104 x  32 0.199 BF\n","   5 conv     32       3 x 3/ 1    104 x 104 x  32 ->  104 x 104 x  32 0.199 BF\n","   6 route  5 4 \t                           ->  104 x 104 x  64 \n","   7 conv     64       1 x 1/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.089 BF\n","   8 route  2 7 \t                           ->  104 x 104 x 128 \n","   9 max                2x 2/ 2    104 x 104 x 128 ->   52 x  52 x 128 0.001 BF\n","  10 conv    128       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.797 BF\n","  11 route  10 \t\t                       1/2 ->   52 x  52 x  64 \n","  12 conv     64       3 x 3/ 1     52 x  52 x  64 ->   52 x  52 x  64 0.199 BF\n","  13 conv     64       3 x 3/ 1     52 x  52 x  64 ->   52 x  52 x  64 0.199 BF\n","  14 route  13 12 \t                           ->   52 x  52 x 128 \n","  15 conv    128       1 x 1/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.089 BF\n","  16 route  10 15 \t                           ->   52 x  52 x 256 \n","  17 max                2x 2/ 2     52 x  52 x 256 ->   26 x  26 x 256 0.001 BF\n","  18 conv    256       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.797 BF\n","  19 route  18 \t\t                       1/2 ->   26 x  26 x 128 \n","  20 conv    128       3 x 3/ 1     26 x  26 x 128 ->   26 x  26 x 128 0.199 BF\n","  21 conv    128       3 x 3/ 1     26 x  26 x 128 ->   26 x  26 x 128 0.199 BF\n","  22 route  21 20 \t                           ->   26 x  26 x 256 \n","  23 conv    256       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.089 BF\n","  24 route  18 23 \t                           ->   26 x  26 x 512 \n","  25 max                2x 2/ 2     26 x  26 x 512 ->   13 x  13 x 512 0.000 BF\n","  26 conv    512       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x 512 0.797 BF\n","  27 conv    256       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x 256 0.044 BF\n","  28 conv    512       3 x 3/ 1     13 x  13 x 256 ->   13 x  13 x 512 0.399 BF\n","  29 conv     24       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x  24 0.004 BF\n","  30 yolo\n","[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.05\n","nms_kind: greedynms (1), beta = 0.600000 \n","  31 route  27 \t\t                           ->   13 x  13 x 256 \n","  32 conv    128       1 x 1/ 1     13 x  13 x 256 ->   13 x  13 x 128 0.011 BF\n","  33 upsample                 2x    13 x  13 x 128 ->   26 x  26 x 128\n","  34 route  33 23 \t                           ->   26 x  26 x 384 \n","  35 conv    256       3 x 3/ 1     26 x  26 x 384 ->   26 x  26 x 256 1.196 BF\n","  36 conv     24       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x  24 0.008 BF\n","  37 yolo\n","[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.05\n","nms_kind: greedynms (1), beta = 0.600000 \n","Total BFLOPS 6.790 \n","avg_outputs = 299930 \n"," Allocate additional workspace_size = 26.22 MB \n","Loading weights from /content/drive/MyDrive/cbe_paper/backup/yolov4-tiny_1000.weights...\n"," seen 64, trained: 64 K-images (1 Kilo-batches_64) \n","Done! Loaded 38 layers from weights-file \n","\n"," calculation mAP (mean average precision)...\n"," Detection layer: 30 - type = 28 \n"," Detection layer: 37 - type = 28 \n","500\n"," detections_count = 9540, unique_truth_count = 1758  \n","class_id = 0, name = marangoni cell, ap = 95.33%   \t (TP = 1583, FP = 540) \n","class_id = 1, name = scale bar, ap = 94.16%   \t (TP = 57, FP = 9) \n","class_id = 2, name = information, ap = 99.76%   \t (TP = 57, FP = 7) \n","\n"," for conf_thresh = 0.25, precision = 0.75, recall = 0.97, F1-score = 0.85 \n"," for conf_thresh = 0.25, TP = 1697, FP = 556, FN = 61, average IoU = 58.74 % \n","\n"," IoU threshold = 50 %, used Area-Under-Curve for each unique Recall \n"," mean average precision (mAP@0.50) = 0.964170, or 96.42 % \n","Total Detection Time: 8 Seconds\n","\n","Set -points flag:\n"," `-points 101` for MS COCO \n"," `-points 11` for PascalVOC 2007 (uncomment `difficult` in voc.data) \n"," `-points 0` (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset\n"]}]},{"cell_type":"code","source":["!/content/darknet/darknet detector map /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/obj.data /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/yolov4-tiny.cfg \"/content/drive/MyDrive/cbe_paper/backup/yolov4-tiny_2000.weights\" -points 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l4DFCrT7n_ZB","executionInfo":{"status":"ok","timestamp":1654864672900,"user_tz":-540,"elapsed":10367,"user":{"displayName":"한동환","userId":"11772705162839800097"}},"outputId":"d874bb07-4f3a-4779-fe92-76d75bf0bfbb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" CUDA-version: 11010 (11020), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n"," CUDNN_HALF=1 \n"," OpenCV version: 3.2.0\n"," 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n","net.optimized_memory = 0 \n","mini_batch = 1, batch = 4, time_steps = 1, train = 0 \n","   layer   filters  size/strd(dil)      input                output\n","   0 Create CUDA-stream - 0 \n"," Create cudnn-handle 0 \n","conv     32       3 x 3/ 2    416 x 416 x   3 ->  208 x 208 x  32 0.075 BF\n","   1 conv     64       3 x 3/ 2    208 x 208 x  32 ->  104 x 104 x  64 0.399 BF\n","   2 conv     64       3 x 3/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.797 BF\n","   3 route  2 \t\t                       1/2 ->  104 x 104 x  32 \n","   4 conv     32       3 x 3/ 1    104 x 104 x  32 ->  104 x 104 x  32 0.199 BF\n","   5 conv     32       3 x 3/ 1    104 x 104 x  32 ->  104 x 104 x  32 0.199 BF\n","   6 route  5 4 \t                           ->  104 x 104 x  64 \n","   7 conv     64       1 x 1/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.089 BF\n","   8 route  2 7 \t                           ->  104 x 104 x 128 \n","   9 max                2x 2/ 2    104 x 104 x 128 ->   52 x  52 x 128 0.001 BF\n","  10 conv    128       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.797 BF\n","  11 route  10 \t\t                       1/2 ->   52 x  52 x  64 \n","  12 conv     64       3 x 3/ 1     52 x  52 x  64 ->   52 x  52 x  64 0.199 BF\n","  13 conv     64       3 x 3/ 1     52 x  52 x  64 ->   52 x  52 x  64 0.199 BF\n","  14 route  13 12 \t                           ->   52 x  52 x 128 \n","  15 conv    128       1 x 1/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.089 BF\n","  16 route  10 15 \t                           ->   52 x  52 x 256 \n","  17 max                2x 2/ 2     52 x  52 x 256 ->   26 x  26 x 256 0.001 BF\n","  18 conv    256       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.797 BF\n","  19 route  18 \t\t                       1/2 ->   26 x  26 x 128 \n","  20 conv    128       3 x 3/ 1     26 x  26 x 128 ->   26 x  26 x 128 0.199 BF\n","  21 conv    128       3 x 3/ 1     26 x  26 x 128 ->   26 x  26 x 128 0.199 BF\n","  22 route  21 20 \t                           ->   26 x  26 x 256 \n","  23 conv    256       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.089 BF\n","  24 route  18 23 \t                           ->   26 x  26 x 512 \n","  25 max                2x 2/ 2     26 x  26 x 512 ->   13 x  13 x 512 0.000 BF\n","  26 conv    512       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x 512 0.797 BF\n","  27 conv    256       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x 256 0.044 BF\n","  28 conv    512       3 x 3/ 1     13 x  13 x 256 ->   13 x  13 x 512 0.399 BF\n","  29 conv     24       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x  24 0.004 BF\n","  30 yolo\n","[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.05\n","nms_kind: greedynms (1), beta = 0.600000 \n","  31 route  27 \t\t                           ->   13 x  13 x 256 \n","  32 conv    128       1 x 1/ 1     13 x  13 x 256 ->   13 x  13 x 128 0.011 BF\n","  33 upsample                 2x    13 x  13 x 128 ->   26 x  26 x 128\n","  34 route  33 23 \t                           ->   26 x  26 x 384 \n","  35 conv    256       3 x 3/ 1     26 x  26 x 384 ->   26 x  26 x 256 1.196 BF\n","  36 conv     24       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x  24 0.008 BF\n","  37 yolo\n","[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.05\n","nms_kind: greedynms (1), beta = 0.600000 \n","Total BFLOPS 6.790 \n","avg_outputs = 299930 \n"," Allocate additional workspace_size = 26.22 MB \n","Loading weights from /content/drive/MyDrive/cbe_paper/backup/yolov4-tiny_2000.weights...\n"," seen 64, trained: 128 K-images (2 Kilo-batches_64) \n","Done! Loaded 38 layers from weights-file \n","\n"," calculation mAP (mean average precision)...\n"," Detection layer: 30 - type = 28 \n"," Detection layer: 37 - type = 28 \n","500\n"," detections_count = 4067, unique_truth_count = 1758  \n","class_id = 0, name = marangoni cell, ap = 95.23%   \t (TP = 1363, FP = 50) \n","class_id = 1, name = scale bar, ap = 100.00%   \t (TP = 57, FP = 39) \n","class_id = 2, name = information, ap = 100.00%   \t (TP = 57, FP = 0) \n","\n"," for conf_thresh = 0.25, precision = 0.94, recall = 0.84, F1-score = 0.89 \n"," for conf_thresh = 0.25, TP = 1477, FP = 89, FN = 281, average IoU = 80.56 % \n","\n"," IoU threshold = 50 %, used Area-Under-Curve for each unique Recall \n"," mean average precision (mAP@0.50) = 0.984109, or 98.41 % \n","Total Detection Time: 8 Seconds\n","\n","Set -points flag:\n"," `-points 101` for MS COCO \n"," `-points 11` for PascalVOC 2007 (uncomment `difficult` in voc.data) \n"," `-points 0` (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset\n"]}]},{"cell_type":"code","source":["!/content/darknet/darknet detector map /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/obj.data /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/yolov4-tiny.cfg \"/content/drive/MyDrive/cbe_paper/backup/yolov4-tiny_3000.weights\" -points 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"96SMB4Ygn_nf","executionInfo":{"status":"ok","timestamp":1654864683059,"user_tz":-540,"elapsed":10163,"user":{"displayName":"한동환","userId":"11772705162839800097"}},"outputId":"e297dc0d-8d80-44ae-9b1b-d547ed51c07c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" CUDA-version: 11010 (11020), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n"," CUDNN_HALF=1 \n"," OpenCV version: 3.2.0\n"," 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n","net.optimized_memory = 0 \n","mini_batch = 1, batch = 4, time_steps = 1, train = 0 \n","   layer   filters  size/strd(dil)      input                output\n","   0 Create CUDA-stream - 0 \n"," Create cudnn-handle 0 \n","conv     32       3 x 3/ 2    416 x 416 x   3 ->  208 x 208 x  32 0.075 BF\n","   1 conv     64       3 x 3/ 2    208 x 208 x  32 ->  104 x 104 x  64 0.399 BF\n","   2 conv     64       3 x 3/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.797 BF\n","   3 route  2 \t\t                       1/2 ->  104 x 104 x  32 \n","   4 conv     32       3 x 3/ 1    104 x 104 x  32 ->  104 x 104 x  32 0.199 BF\n","   5 conv     32       3 x 3/ 1    104 x 104 x  32 ->  104 x 104 x  32 0.199 BF\n","   6 route  5 4 \t                           ->  104 x 104 x  64 \n","   7 conv     64       1 x 1/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.089 BF\n","   8 route  2 7 \t                           ->  104 x 104 x 128 \n","   9 max                2x 2/ 2    104 x 104 x 128 ->   52 x  52 x 128 0.001 BF\n","  10 conv    128       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.797 BF\n","  11 route  10 \t\t                       1/2 ->   52 x  52 x  64 \n","  12 conv     64       3 x 3/ 1     52 x  52 x  64 ->   52 x  52 x  64 0.199 BF\n","  13 conv     64       3 x 3/ 1     52 x  52 x  64 ->   52 x  52 x  64 0.199 BF\n","  14 route  13 12 \t                           ->   52 x  52 x 128 \n","  15 conv    128       1 x 1/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.089 BF\n","  16 route  10 15 \t                           ->   52 x  52 x 256 \n","  17 max                2x 2/ 2     52 x  52 x 256 ->   26 x  26 x 256 0.001 BF\n","  18 conv    256       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.797 BF\n","  19 route  18 \t\t                       1/2 ->   26 x  26 x 128 \n","  20 conv    128       3 x 3/ 1     26 x  26 x 128 ->   26 x  26 x 128 0.199 BF\n","  21 conv    128       3 x 3/ 1     26 x  26 x 128 ->   26 x  26 x 128 0.199 BF\n","  22 route  21 20 \t                           ->   26 x  26 x 256 \n","  23 conv    256       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.089 BF\n","  24 route  18 23 \t                           ->   26 x  26 x 512 \n","  25 max                2x 2/ 2     26 x  26 x 512 ->   13 x  13 x 512 0.000 BF\n","  26 conv    512       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x 512 0.797 BF\n","  27 conv    256       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x 256 0.044 BF\n","  28 conv    512       3 x 3/ 1     13 x  13 x 256 ->   13 x  13 x 512 0.399 BF\n","  29 conv     24       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x  24 0.004 BF\n","  30 yolo\n","[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.05\n","nms_kind: greedynms (1), beta = 0.600000 \n","  31 route  27 \t\t                           ->   13 x  13 x 256 \n","  32 conv    128       1 x 1/ 1     13 x  13 x 256 ->   13 x  13 x 128 0.011 BF\n","  33 upsample                 2x    13 x  13 x 128 ->   26 x  26 x 128\n","  34 route  33 23 \t                           ->   26 x  26 x 384 \n","  35 conv    256       3 x 3/ 1     26 x  26 x 384 ->   26 x  26 x 256 1.196 BF\n","  36 conv     24       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x  24 0.008 BF\n","  37 yolo\n","[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.05\n","nms_kind: greedynms (1), beta = 0.600000 \n","Total BFLOPS 6.790 \n","avg_outputs = 299930 \n"," Allocate additional workspace_size = 26.22 MB \n","Loading weights from /content/drive/MyDrive/cbe_paper/backup/yolov4-tiny_3000.weights...\n"," seen 64, trained: 192 K-images (3 Kilo-batches_64) \n","Done! Loaded 38 layers from weights-file \n","\n"," calculation mAP (mean average precision)...\n"," Detection layer: 30 - type = 28 \n"," Detection layer: 37 - type = 28 \n","500\n"," detections_count = 3779, unique_truth_count = 1758  \n","class_id = 0, name = marangoni cell, ap = 99.63%   \t (TP = 1632, FP = 149) \n","class_id = 1, name = scale bar, ap = 100.00%   \t (TP = 57, FP = 2) \n","class_id = 2, name = information, ap = 100.00%   \t (TP = 57, FP = 0) \n","\n"," for conf_thresh = 0.25, precision = 0.92, recall = 0.99, F1-score = 0.96 \n"," for conf_thresh = 0.25, TP = 1746, FP = 151, FN = 12, average IoU = 77.63 % \n","\n"," IoU threshold = 50 %, used Area-Under-Curve for each unique Recall \n"," mean average precision (mAP@0.50) = 0.998753, or 99.88 % \n","Total Detection Time: 8 Seconds\n","\n","Set -points flag:\n"," `-points 101` for MS COCO \n"," `-points 11` for PascalVOC 2007 (uncomment `difficult` in voc.data) \n"," `-points 0` (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset\n"]}]},{"cell_type":"code","source":["!/content/darknet/darknet detector map /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/obj.data /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/yolov4-tiny.cfg \"/content/drive/MyDrive/cbe_paper/backup/yolov4-tiny_4000.weights\" -points 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hdv2FZdan_1r","executionInfo":{"status":"ok","timestamp":1654864693361,"user_tz":-540,"elapsed":10307,"user":{"displayName":"한동환","userId":"11772705162839800097"}},"outputId":"0bba6212-1a84-4f56-ff87-cc5d2f8b9b17"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" CUDA-version: 11010 (11020), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n"," CUDNN_HALF=1 \n"," OpenCV version: 3.2.0\n"," 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n","net.optimized_memory = 0 \n","mini_batch = 1, batch = 4, time_steps = 1, train = 0 \n","   layer   filters  size/strd(dil)      input                output\n","   0 Create CUDA-stream - 0 \n"," Create cudnn-handle 0 \n","conv     32       3 x 3/ 2    416 x 416 x   3 ->  208 x 208 x  32 0.075 BF\n","   1 conv     64       3 x 3/ 2    208 x 208 x  32 ->  104 x 104 x  64 0.399 BF\n","   2 conv     64       3 x 3/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.797 BF\n","   3 route  2 \t\t                       1/2 ->  104 x 104 x  32 \n","   4 conv     32       3 x 3/ 1    104 x 104 x  32 ->  104 x 104 x  32 0.199 BF\n","   5 conv     32       3 x 3/ 1    104 x 104 x  32 ->  104 x 104 x  32 0.199 BF\n","   6 route  5 4 \t                           ->  104 x 104 x  64 \n","   7 conv     64       1 x 1/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.089 BF\n","   8 route  2 7 \t                           ->  104 x 104 x 128 \n","   9 max                2x 2/ 2    104 x 104 x 128 ->   52 x  52 x 128 0.001 BF\n","  10 conv    128       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.797 BF\n","  11 route  10 \t\t                       1/2 ->   52 x  52 x  64 \n","  12 conv     64       3 x 3/ 1     52 x  52 x  64 ->   52 x  52 x  64 0.199 BF\n","  13 conv     64       3 x 3/ 1     52 x  52 x  64 ->   52 x  52 x  64 0.199 BF\n","  14 route  13 12 \t                           ->   52 x  52 x 128 \n","  15 conv    128       1 x 1/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.089 BF\n","  16 route  10 15 \t                           ->   52 x  52 x 256 \n","  17 max                2x 2/ 2     52 x  52 x 256 ->   26 x  26 x 256 0.001 BF\n","  18 conv    256       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.797 BF\n","  19 route  18 \t\t                       1/2 ->   26 x  26 x 128 \n","  20 conv    128       3 x 3/ 1     26 x  26 x 128 ->   26 x  26 x 128 0.199 BF\n","  21 conv    128       3 x 3/ 1     26 x  26 x 128 ->   26 x  26 x 128 0.199 BF\n","  22 route  21 20 \t                           ->   26 x  26 x 256 \n","  23 conv    256       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.089 BF\n","  24 route  18 23 \t                           ->   26 x  26 x 512 \n","  25 max                2x 2/ 2     26 x  26 x 512 ->   13 x  13 x 512 0.000 BF\n","  26 conv    512       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x 512 0.797 BF\n","  27 conv    256       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x 256 0.044 BF\n","  28 conv    512       3 x 3/ 1     13 x  13 x 256 ->   13 x  13 x 512 0.399 BF\n","  29 conv     24       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x  24 0.004 BF\n","  30 yolo\n","[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.05\n","nms_kind: greedynms (1), beta = 0.600000 \n","  31 route  27 \t\t                           ->   13 x  13 x 256 \n","  32 conv    128       1 x 1/ 1     13 x  13 x 256 ->   13 x  13 x 128 0.011 BF\n","  33 upsample                 2x    13 x  13 x 128 ->   26 x  26 x 128\n","  34 route  33 23 \t                           ->   26 x  26 x 384 \n","  35 conv    256       3 x 3/ 1     26 x  26 x 384 ->   26 x  26 x 256 1.196 BF\n","  36 conv     24       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x  24 0.008 BF\n","  37 yolo\n","[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.05\n","nms_kind: greedynms (1), beta = 0.600000 \n","Total BFLOPS 6.790 \n","avg_outputs = 299930 \n"," Allocate additional workspace_size = 26.22 MB \n","Loading weights from /content/drive/MyDrive/cbe_paper/backup/yolov4-tiny_4000.weights...\n"," seen 64, trained: 256 K-images (4 Kilo-batches_64) \n","Done! Loaded 38 layers from weights-file \n","\n"," calculation mAP (mean average precision)...\n"," Detection layer: 30 - type = 28 \n"," Detection layer: 37 - type = 28 \n","500\n"," detections_count = 2846, unique_truth_count = 1758  \n","class_id = 0, name = marangoni cell, ap = 99.54%   \t (TP = 1624, FP = 67) \n","class_id = 1, name = scale bar, ap = 100.00%   \t (TP = 57, FP = 0) \n","class_id = 2, name = information, ap = 100.00%   \t (TP = 57, FP = 0) \n","\n"," for conf_thresh = 0.25, precision = 0.96, recall = 0.99, F1-score = 0.98 \n"," for conf_thresh = 0.25, TP = 1738, FP = 67, FN = 20, average IoU = 85.86 % \n","\n"," IoU threshold = 50 %, used Area-Under-Curve for each unique Recall \n"," mean average precision (mAP@0.50) = 0.998462, or 99.85 % \n","Total Detection Time: 8 Seconds\n","\n","Set -points flag:\n"," `-points 101` for MS COCO \n"," `-points 11` for PascalVOC 2007 (uncomment `difficult` in voc.data) \n"," `-points 0` (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset\n"]}]},{"cell_type":"code","source":["!/content/darknet/darknet detector map /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/obj.data /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/yolov4-tiny.cfg \"/content/drive/MyDrive/cbe_paper/backup/yolov4-tiny_5000.weights\" -points 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vlN8w73uoAHb","executionInfo":{"status":"ok","timestamp":1654864703278,"user_tz":-540,"elapsed":9933,"user":{"displayName":"한동환","userId":"11772705162839800097"}},"outputId":"fb36d9ad-3480-4ee5-84fd-5447cde05553"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" CUDA-version: 11010 (11020), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n"," CUDNN_HALF=1 \n"," OpenCV version: 3.2.0\n"," 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n","net.optimized_memory = 0 \n","mini_batch = 1, batch = 4, time_steps = 1, train = 0 \n","   layer   filters  size/strd(dil)      input                output\n","   0 Create CUDA-stream - 0 \n"," Create cudnn-handle 0 \n","conv     32       3 x 3/ 2    416 x 416 x   3 ->  208 x 208 x  32 0.075 BF\n","   1 conv     64       3 x 3/ 2    208 x 208 x  32 ->  104 x 104 x  64 0.399 BF\n","   2 conv     64       3 x 3/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.797 BF\n","   3 route  2 \t\t                       1/2 ->  104 x 104 x  32 \n","   4 conv     32       3 x 3/ 1    104 x 104 x  32 ->  104 x 104 x  32 0.199 BF\n","   5 conv     32       3 x 3/ 1    104 x 104 x  32 ->  104 x 104 x  32 0.199 BF\n","   6 route  5 4 \t                           ->  104 x 104 x  64 \n","   7 conv     64       1 x 1/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.089 BF\n","   8 route  2 7 \t                           ->  104 x 104 x 128 \n","   9 max                2x 2/ 2    104 x 104 x 128 ->   52 x  52 x 128 0.001 BF\n","  10 conv    128       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.797 BF\n","  11 route  10 \t\t                       1/2 ->   52 x  52 x  64 \n","  12 conv     64       3 x 3/ 1     52 x  52 x  64 ->   52 x  52 x  64 0.199 BF\n","  13 conv     64       3 x 3/ 1     52 x  52 x  64 ->   52 x  52 x  64 0.199 BF\n","  14 route  13 12 \t                           ->   52 x  52 x 128 \n","  15 conv    128       1 x 1/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.089 BF\n","  16 route  10 15 \t                           ->   52 x  52 x 256 \n","  17 max                2x 2/ 2     52 x  52 x 256 ->   26 x  26 x 256 0.001 BF\n","  18 conv    256       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.797 BF\n","  19 route  18 \t\t                       1/2 ->   26 x  26 x 128 \n","  20 conv    128       3 x 3/ 1     26 x  26 x 128 ->   26 x  26 x 128 0.199 BF\n","  21 conv    128       3 x 3/ 1     26 x  26 x 128 ->   26 x  26 x 128 0.199 BF\n","  22 route  21 20 \t                           ->   26 x  26 x 256 \n","  23 conv    256       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.089 BF\n","  24 route  18 23 \t                           ->   26 x  26 x 512 \n","  25 max                2x 2/ 2     26 x  26 x 512 ->   13 x  13 x 512 0.000 BF\n","  26 conv    512       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x 512 0.797 BF\n","  27 conv    256       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x 256 0.044 BF\n","  28 conv    512       3 x 3/ 1     13 x  13 x 256 ->   13 x  13 x 512 0.399 BF\n","  29 conv     24       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x  24 0.004 BF\n","  30 yolo\n","[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.05\n","nms_kind: greedynms (1), beta = 0.600000 \n","  31 route  27 \t\t                           ->   13 x  13 x 256 \n","  32 conv    128       1 x 1/ 1     13 x  13 x 256 ->   13 x  13 x 128 0.011 BF\n","  33 upsample                 2x    13 x  13 x 128 ->   26 x  26 x 128\n","  34 route  33 23 \t                           ->   26 x  26 x 384 \n","  35 conv    256       3 x 3/ 1     26 x  26 x 384 ->   26 x  26 x 256 1.196 BF\n","  36 conv     24       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x  24 0.008 BF\n","  37 yolo\n","[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.05\n","nms_kind: greedynms (1), beta = 0.600000 \n","Total BFLOPS 6.790 \n","avg_outputs = 299930 \n"," Allocate additional workspace_size = 26.22 MB \n","Loading weights from /content/drive/MyDrive/cbe_paper/backup/yolov4-tiny_5000.weights...\n"," seen 64, trained: 320 K-images (5 Kilo-batches_64) \n","Done! Loaded 38 layers from weights-file \n","\n"," calculation mAP (mean average precision)...\n"," Detection layer: 30 - type = 28 \n"," Detection layer: 37 - type = 28 \n","500\n"," detections_count = 2773, unique_truth_count = 1758  \n","class_id = 0, name = marangoni cell, ap = 73.59%   \t (TP = 821, FP = 39) \n","class_id = 1, name = scale bar, ap = 100.00%   \t (TP = 57, FP = 0) \n","class_id = 2, name = information, ap = 100.00%   \t (TP = 57, FP = 0) \n","\n"," for conf_thresh = 0.25, precision = 0.96, recall = 0.53, F1-score = 0.68 \n"," for conf_thresh = 0.25, TP = 935, FP = 39, FN = 823, average IoU = 79.96 % \n","\n"," IoU threshold = 50 %, used Area-Under-Curve for each unique Recall \n"," mean average precision (mAP@0.50) = 0.911982, or 91.20 % \n","Total Detection Time: 9 Seconds\n","\n","Set -points flag:\n"," `-points 101` for MS COCO \n"," `-points 11` for PascalVOC 2007 (uncomment `difficult` in voc.data) \n"," `-points 0` (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset\n"]}]},{"cell_type":"code","source":["!/content/darknet/darknet detector map /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/obj.data /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/yolov4-tiny.cfg \"/content/drive/MyDrive/cbe_paper/backup/yolov4-tiny_6000.weights\" -points 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hWKb_z4AoASs","executionInfo":{"status":"ok","timestamp":1654864713966,"user_tz":-540,"elapsed":10704,"user":{"displayName":"한동환","userId":"11772705162839800097"}},"outputId":"220e25ee-3a7a-4efb-b8b9-46932111c47c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" CUDA-version: 11010 (11020), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n"," CUDNN_HALF=1 \n"," OpenCV version: 3.2.0\n"," 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n","net.optimized_memory = 0 \n","mini_batch = 1, batch = 4, time_steps = 1, train = 0 \n","   layer   filters  size/strd(dil)      input                output\n","   0 Create CUDA-stream - 0 \n"," Create cudnn-handle 0 \n","conv     32       3 x 3/ 2    416 x 416 x   3 ->  208 x 208 x  32 0.075 BF\n","   1 conv     64       3 x 3/ 2    208 x 208 x  32 ->  104 x 104 x  64 0.399 BF\n","   2 conv     64       3 x 3/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.797 BF\n","   3 route  2 \t\t                       1/2 ->  104 x 104 x  32 \n","   4 conv     32       3 x 3/ 1    104 x 104 x  32 ->  104 x 104 x  32 0.199 BF\n","   5 conv     32       3 x 3/ 1    104 x 104 x  32 ->  104 x 104 x  32 0.199 BF\n","   6 route  5 4 \t                           ->  104 x 104 x  64 \n","   7 conv     64       1 x 1/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.089 BF\n","   8 route  2 7 \t                           ->  104 x 104 x 128 \n","   9 max                2x 2/ 2    104 x 104 x 128 ->   52 x  52 x 128 0.001 BF\n","  10 conv    128       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.797 BF\n","  11 route  10 \t\t                       1/2 ->   52 x  52 x  64 \n","  12 conv     64       3 x 3/ 1     52 x  52 x  64 ->   52 x  52 x  64 0.199 BF\n","  13 conv     64       3 x 3/ 1     52 x  52 x  64 ->   52 x  52 x  64 0.199 BF\n","  14 route  13 12 \t                           ->   52 x  52 x 128 \n","  15 conv    128       1 x 1/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.089 BF\n","  16 route  10 15 \t                           ->   52 x  52 x 256 \n","  17 max                2x 2/ 2     52 x  52 x 256 ->   26 x  26 x 256 0.001 BF\n","  18 conv    256       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.797 BF\n","  19 route  18 \t\t                       1/2 ->   26 x  26 x 128 \n","  20 conv    128       3 x 3/ 1     26 x  26 x 128 ->   26 x  26 x 128 0.199 BF\n","  21 conv    128       3 x 3/ 1     26 x  26 x 128 ->   26 x  26 x 128 0.199 BF\n","  22 route  21 20 \t                           ->   26 x  26 x 256 \n","  23 conv    256       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.089 BF\n","  24 route  18 23 \t                           ->   26 x  26 x 512 \n","  25 max                2x 2/ 2     26 x  26 x 512 ->   13 x  13 x 512 0.000 BF\n","  26 conv    512       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x 512 0.797 BF\n","  27 conv    256       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x 256 0.044 BF\n","  28 conv    512       3 x 3/ 1     13 x  13 x 256 ->   13 x  13 x 512 0.399 BF\n","  29 conv     24       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x  24 0.004 BF\n","  30 yolo\n","[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.05\n","nms_kind: greedynms (1), beta = 0.600000 \n","  31 route  27 \t\t                           ->   13 x  13 x 256 \n","  32 conv    128       1 x 1/ 1     13 x  13 x 256 ->   13 x  13 x 128 0.011 BF\n","  33 upsample                 2x    13 x  13 x 128 ->   26 x  26 x 128\n","  34 route  33 23 \t                           ->   26 x  26 x 384 \n","  35 conv    256       3 x 3/ 1     26 x  26 x 384 ->   26 x  26 x 256 1.196 BF\n","  36 conv     24       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x  24 0.008 BF\n","  37 yolo\n","[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.05\n","nms_kind: greedynms (1), beta = 0.600000 \n","Total BFLOPS 6.790 \n","avg_outputs = 299930 \n"," Allocate additional workspace_size = 26.22 MB \n","Loading weights from /content/drive/MyDrive/cbe_paper/backup/yolov4-tiny_6000.weights...\n"," seen 64, trained: 384 K-images (6 Kilo-batches_64) \n","Done! Loaded 38 layers from weights-file \n","\n"," calculation mAP (mean average precision)...\n"," Detection layer: 30 - type = 28 \n"," Detection layer: 37 - type = 28 \n","500\n"," detections_count = 2742, unique_truth_count = 1758  \n","class_id = 0, name = marangoni cell, ap = 97.27%   \t (TP = 1443, FP = 38) \n","class_id = 1, name = scale bar, ap = 100.00%   \t (TP = 57, FP = 0) \n","class_id = 2, name = information, ap = 100.00%   \t (TP = 57, FP = 0) \n","\n"," for conf_thresh = 0.25, precision = 0.98, recall = 0.89, F1-score = 0.93 \n"," for conf_thresh = 0.25, TP = 1557, FP = 38, FN = 201, average IoU = 84.69 % \n","\n"," IoU threshold = 50 %, used Area-Under-Curve for each unique Recall \n"," mean average precision (mAP@0.50) = 0.990891, or 99.09 % \n","Total Detection Time: 9 Seconds\n","\n","Set -points flag:\n"," `-points 101` for MS COCO \n"," `-points 11` for PascalVOC 2007 (uncomment `difficult` in voc.data) \n"," `-points 0` (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset\n"]}]},{"cell_type":"code","source":["!/content/darknet/darknet detector map /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/obj.data /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/yolov4-tiny.cfg \"/content/drive/MyDrive/cbe_paper/backup/yolov4-tiny_7000.weights\" -points 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HLXbLNxjoAe9","executionInfo":{"status":"ok","timestamp":1654864723762,"user_tz":-540,"elapsed":9802,"user":{"displayName":"한동환","userId":"11772705162839800097"}},"outputId":"5806665f-4c02-4e3b-8ba6-f8e74d9578dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" CUDA-version: 11010 (11020), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n"," CUDNN_HALF=1 \n"," OpenCV version: 3.2.0\n"," 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n","net.optimized_memory = 0 \n","mini_batch = 1, batch = 4, time_steps = 1, train = 0 \n","   layer   filters  size/strd(dil)      input                output\n","   0 Create CUDA-stream - 0 \n"," Create cudnn-handle 0 \n","conv     32       3 x 3/ 2    416 x 416 x   3 ->  208 x 208 x  32 0.075 BF\n","   1 conv     64       3 x 3/ 2    208 x 208 x  32 ->  104 x 104 x  64 0.399 BF\n","   2 conv     64       3 x 3/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.797 BF\n","   3 route  2 \t\t                       1/2 ->  104 x 104 x  32 \n","   4 conv     32       3 x 3/ 1    104 x 104 x  32 ->  104 x 104 x  32 0.199 BF\n","   5 conv     32       3 x 3/ 1    104 x 104 x  32 ->  104 x 104 x  32 0.199 BF\n","   6 route  5 4 \t                           ->  104 x 104 x  64 \n","   7 conv     64       1 x 1/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.089 BF\n","   8 route  2 7 \t                           ->  104 x 104 x 128 \n","   9 max                2x 2/ 2    104 x 104 x 128 ->   52 x  52 x 128 0.001 BF\n","  10 conv    128       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.797 BF\n","  11 route  10 \t\t                       1/2 ->   52 x  52 x  64 \n","  12 conv     64       3 x 3/ 1     52 x  52 x  64 ->   52 x  52 x  64 0.199 BF\n","  13 conv     64       3 x 3/ 1     52 x  52 x  64 ->   52 x  52 x  64 0.199 BF\n","  14 route  13 12 \t                           ->   52 x  52 x 128 \n","  15 conv    128       1 x 1/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.089 BF\n","  16 route  10 15 \t                           ->   52 x  52 x 256 \n","  17 max                2x 2/ 2     52 x  52 x 256 ->   26 x  26 x 256 0.001 BF\n","  18 conv    256       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.797 BF\n","  19 route  18 \t\t                       1/2 ->   26 x  26 x 128 \n","  20 conv    128       3 x 3/ 1     26 x  26 x 128 ->   26 x  26 x 128 0.199 BF\n","  21 conv    128       3 x 3/ 1     26 x  26 x 128 ->   26 x  26 x 128 0.199 BF\n","  22 route  21 20 \t                           ->   26 x  26 x 256 \n","  23 conv    256       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.089 BF\n","  24 route  18 23 \t                           ->   26 x  26 x 512 \n","  25 max                2x 2/ 2     26 x  26 x 512 ->   13 x  13 x 512 0.000 BF\n","  26 conv    512       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x 512 0.797 BF\n","  27 conv    256       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x 256 0.044 BF\n","  28 conv    512       3 x 3/ 1     13 x  13 x 256 ->   13 x  13 x 512 0.399 BF\n","  29 conv     24       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x  24 0.004 BF\n","  30 yolo\n","[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.05\n","nms_kind: greedynms (1), beta = 0.600000 \n","  31 route  27 \t\t                           ->   13 x  13 x 256 \n","  32 conv    128       1 x 1/ 1     13 x  13 x 256 ->   13 x  13 x 128 0.011 BF\n","  33 upsample                 2x    13 x  13 x 128 ->   26 x  26 x 128\n","  34 route  33 23 \t                           ->   26 x  26 x 384 \n","  35 conv    256       3 x 3/ 1     26 x  26 x 384 ->   26 x  26 x 256 1.196 BF\n","  36 conv     24       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x  24 0.008 BF\n","  37 yolo\n","[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.05\n","nms_kind: greedynms (1), beta = 0.600000 \n","Total BFLOPS 6.790 \n","avg_outputs = 299930 \n"," Allocate additional workspace_size = 26.22 MB \n","Loading weights from /content/drive/MyDrive/cbe_paper/backup/yolov4-tiny_7000.weights...\n"," seen 64, trained: 448 K-images (7 Kilo-batches_64) \n","Done! Loaded 38 layers from weights-file \n","\n"," calculation mAP (mean average precision)...\n"," Detection layer: 30 - type = 28 \n"," Detection layer: 37 - type = 28 \n","500\n"," detections_count = 2409, unique_truth_count = 1758  \n","class_id = 0, name = marangoni cell, ap = 99.67%   \t (TP = 1625, FP = 45) \n","class_id = 1, name = scale bar, ap = 100.00%   \t (TP = 57, FP = 0) \n","class_id = 2, name = information, ap = 100.00%   \t (TP = 57, FP = 0) \n","\n"," for conf_thresh = 0.25, precision = 0.97, recall = 0.99, F1-score = 0.98 \n"," for conf_thresh = 0.25, TP = 1739, FP = 45, FN = 19, average IoU = 86.87 % \n","\n"," IoU threshold = 50 %, used Area-Under-Curve for each unique Recall \n"," mean average precision (mAP@0.50) = 0.998910, or 99.89 % \n","Total Detection Time: 8 Seconds\n","\n","Set -points flag:\n"," `-points 101` for MS COCO \n"," `-points 11` for PascalVOC 2007 (uncomment `difficult` in voc.data) \n"," `-points 0` (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset\n"]}]},{"cell_type":"code","source":["!/content/darknet/darknet detector map /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/obj.data /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/yolov4-tiny.cfg \"/content/drive/MyDrive/cbe_paper/backup/yolov4-tiny_8000.weights\" -points 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LsyurRkGoAqG","executionInfo":{"status":"ok","timestamp":1654864735317,"user_tz":-540,"elapsed":11573,"user":{"displayName":"한동환","userId":"11772705162839800097"}},"outputId":"f78778cb-63a1-4293-8aea-299e632470e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" CUDA-version: 11010 (11020), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n"," CUDNN_HALF=1 \n"," OpenCV version: 3.2.0\n"," 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n","net.optimized_memory = 0 \n","mini_batch = 1, batch = 4, time_steps = 1, train = 0 \n","   layer   filters  size/strd(dil)      input                output\n","   0 Create CUDA-stream - 0 \n"," Create cudnn-handle 0 \n","conv     32       3 x 3/ 2    416 x 416 x   3 ->  208 x 208 x  32 0.075 BF\n","   1 conv     64       3 x 3/ 2    208 x 208 x  32 ->  104 x 104 x  64 0.399 BF\n","   2 conv     64       3 x 3/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.797 BF\n","   3 route  2 \t\t                       1/2 ->  104 x 104 x  32 \n","   4 conv     32       3 x 3/ 1    104 x 104 x  32 ->  104 x 104 x  32 0.199 BF\n","   5 conv     32       3 x 3/ 1    104 x 104 x  32 ->  104 x 104 x  32 0.199 BF\n","   6 route  5 4 \t                           ->  104 x 104 x  64 \n","   7 conv     64       1 x 1/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.089 BF\n","   8 route  2 7 \t                           ->  104 x 104 x 128 \n","   9 max                2x 2/ 2    104 x 104 x 128 ->   52 x  52 x 128 0.001 BF\n","  10 conv    128       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.797 BF\n","  11 route  10 \t\t                       1/2 ->   52 x  52 x  64 \n","  12 conv     64       3 x 3/ 1     52 x  52 x  64 ->   52 x  52 x  64 0.199 BF\n","  13 conv     64       3 x 3/ 1     52 x  52 x  64 ->   52 x  52 x  64 0.199 BF\n","  14 route  13 12 \t                           ->   52 x  52 x 128 \n","  15 conv    128       1 x 1/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.089 BF\n","  16 route  10 15 \t                           ->   52 x  52 x 256 \n","  17 max                2x 2/ 2     52 x  52 x 256 ->   26 x  26 x 256 0.001 BF\n","  18 conv    256       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.797 BF\n","  19 route  18 \t\t                       1/2 ->   26 x  26 x 128 \n","  20 conv    128       3 x 3/ 1     26 x  26 x 128 ->   26 x  26 x 128 0.199 BF\n","  21 conv    128       3 x 3/ 1     26 x  26 x 128 ->   26 x  26 x 128 0.199 BF\n","  22 route  21 20 \t                           ->   26 x  26 x 256 \n","  23 conv    256       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.089 BF\n","  24 route  18 23 \t                           ->   26 x  26 x 512 \n","  25 max                2x 2/ 2     26 x  26 x 512 ->   13 x  13 x 512 0.000 BF\n","  26 conv    512       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x 512 0.797 BF\n","  27 conv    256       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x 256 0.044 BF\n","  28 conv    512       3 x 3/ 1     13 x  13 x 256 ->   13 x  13 x 512 0.399 BF\n","  29 conv     24       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x  24 0.004 BF\n","  30 yolo\n","[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.05\n","nms_kind: greedynms (1), beta = 0.600000 \n","  31 route  27 \t\t                           ->   13 x  13 x 256 \n","  32 conv    128       1 x 1/ 1     13 x  13 x 256 ->   13 x  13 x 128 0.011 BF\n","  33 upsample                 2x    13 x  13 x 128 ->   26 x  26 x 128\n","  34 route  33 23 \t                           ->   26 x  26 x 384 \n","  35 conv    256       3 x 3/ 1     26 x  26 x 384 ->   26 x  26 x 256 1.196 BF\n","  36 conv     24       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x  24 0.008 BF\n","  37 yolo\n","[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.05\n","nms_kind: greedynms (1), beta = 0.600000 \n","Total BFLOPS 6.790 \n","avg_outputs = 299930 \n"," Allocate additional workspace_size = 26.22 MB \n","Loading weights from /content/drive/MyDrive/cbe_paper/backup/yolov4-tiny_8000.weights...\n"," seen 64, trained: 512 K-images (8 Kilo-batches_64) \n","Done! Loaded 38 layers from weights-file \n","\n"," calculation mAP (mean average precision)...\n"," Detection layer: 30 - type = 28 \n"," Detection layer: 37 - type = 28 \n","500\n"," detections_count = 2374, unique_truth_count = 1758  \n","class_id = 0, name = marangoni cell, ap = 99.80%   \t (TP = 1627, FP = 40) \n","class_id = 1, name = scale bar, ap = 100.00%   \t (TP = 57, FP = 0) \n","class_id = 2, name = information, ap = 100.00%   \t (TP = 57, FP = 0) \n","\n"," for conf_thresh = 0.25, precision = 0.98, recall = 0.99, F1-score = 0.98 \n"," for conf_thresh = 0.25, TP = 1741, FP = 40, FN = 17, average IoU = 86.92 % \n","\n"," IoU threshold = 50 %, used Area-Under-Curve for each unique Recall \n"," mean average precision (mAP@0.50) = 0.999317, or 99.93 % \n","Total Detection Time: 10 Seconds\n","\n","Set -points flag:\n"," `-points 101` for MS COCO \n"," `-points 11` for PascalVOC 2007 (uncomment `difficult` in voc.data) \n"," `-points 0` (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset\n"]}]},{"cell_type":"code","source":["!/content/darknet/darknet detector map /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/obj.data /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/yolov4-tiny.cfg \"/content/drive/MyDrive/cbe_paper/backup/yolov4-tiny_9000.weights\" -points 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dJ8-_DiYoA0_","executionInfo":{"status":"ok","timestamp":1654864745481,"user_tz":-540,"elapsed":10179,"user":{"displayName":"한동환","userId":"11772705162839800097"}},"outputId":"c50b1930-e07f-4dd3-c6d6-ed98fc950466"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" CUDA-version: 11010 (11020), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n"," CUDNN_HALF=1 \n"," OpenCV version: 3.2.0\n"," 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n","net.optimized_memory = 0 \n","mini_batch = 1, batch = 4, time_steps = 1, train = 0 \n","   layer   filters  size/strd(dil)      input                output\n","   0 Create CUDA-stream - 0 \n"," Create cudnn-handle 0 \n","conv     32       3 x 3/ 2    416 x 416 x   3 ->  208 x 208 x  32 0.075 BF\n","   1 conv     64       3 x 3/ 2    208 x 208 x  32 ->  104 x 104 x  64 0.399 BF\n","   2 conv     64       3 x 3/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.797 BF\n","   3 route  2 \t\t                       1/2 ->  104 x 104 x  32 \n","   4 conv     32       3 x 3/ 1    104 x 104 x  32 ->  104 x 104 x  32 0.199 BF\n","   5 conv     32       3 x 3/ 1    104 x 104 x  32 ->  104 x 104 x  32 0.199 BF\n","   6 route  5 4 \t                           ->  104 x 104 x  64 \n","   7 conv     64       1 x 1/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.089 BF\n","   8 route  2 7 \t                           ->  104 x 104 x 128 \n","   9 max                2x 2/ 2    104 x 104 x 128 ->   52 x  52 x 128 0.001 BF\n","  10 conv    128       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.797 BF\n","  11 route  10 \t\t                       1/2 ->   52 x  52 x  64 \n","  12 conv     64       3 x 3/ 1     52 x  52 x  64 ->   52 x  52 x  64 0.199 BF\n","  13 conv     64       3 x 3/ 1     52 x  52 x  64 ->   52 x  52 x  64 0.199 BF\n","  14 route  13 12 \t                           ->   52 x  52 x 128 \n","  15 conv    128       1 x 1/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.089 BF\n","  16 route  10 15 \t                           ->   52 x  52 x 256 \n","  17 max                2x 2/ 2     52 x  52 x 256 ->   26 x  26 x 256 0.001 BF\n","  18 conv    256       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.797 BF\n","  19 route  18 \t\t                       1/2 ->   26 x  26 x 128 \n","  20 conv    128       3 x 3/ 1     26 x  26 x 128 ->   26 x  26 x 128 0.199 BF\n","  21 conv    128       3 x 3/ 1     26 x  26 x 128 ->   26 x  26 x 128 0.199 BF\n","  22 route  21 20 \t                           ->   26 x  26 x 256 \n","  23 conv    256       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.089 BF\n","  24 route  18 23 \t                           ->   26 x  26 x 512 \n","  25 max                2x 2/ 2     26 x  26 x 512 ->   13 x  13 x 512 0.000 BF\n","  26 conv    512       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x 512 0.797 BF\n","  27 conv    256       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x 256 0.044 BF\n","  28 conv    512       3 x 3/ 1     13 x  13 x 256 ->   13 x  13 x 512 0.399 BF\n","  29 conv     24       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x  24 0.004 BF\n","  30 yolo\n","[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.05\n","nms_kind: greedynms (1), beta = 0.600000 \n","  31 route  27 \t\t                           ->   13 x  13 x 256 \n","  32 conv    128       1 x 1/ 1     13 x  13 x 256 ->   13 x  13 x 128 0.011 BF\n","  33 upsample                 2x    13 x  13 x 128 ->   26 x  26 x 128\n","  34 route  33 23 \t                           ->   26 x  26 x 384 \n","  35 conv    256       3 x 3/ 1     26 x  26 x 384 ->   26 x  26 x 256 1.196 BF\n","  36 conv     24       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x  24 0.008 BF\n","  37 yolo\n","[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.05\n","nms_kind: greedynms (1), beta = 0.600000 \n","Total BFLOPS 6.790 \n","avg_outputs = 299930 \n"," Allocate additional workspace_size = 26.22 MB \n","Loading weights from /content/drive/MyDrive/cbe_paper/backup/yolov4-tiny_9000.weights...\n"," seen 64, trained: 576 K-images (9 Kilo-batches_64) \n","Done! Loaded 38 layers from weights-file \n","\n"," calculation mAP (mean average precision)...\n"," Detection layer: 30 - type = 28 \n"," Detection layer: 37 - type = 28 \n","500\n"," detections_count = 2200, unique_truth_count = 1758  \n","class_id = 0, name = marangoni cell, ap = 99.83%   \t (TP = 1632, FP = 29) \n","class_id = 1, name = scale bar, ap = 100.00%   \t (TP = 57, FP = 0) \n","class_id = 2, name = information, ap = 100.00%   \t (TP = 57, FP = 0) \n","\n"," for conf_thresh = 0.25, precision = 0.98, recall = 0.99, F1-score = 0.99 \n"," for conf_thresh = 0.25, TP = 1746, FP = 29, FN = 12, average IoU = 91.17 % \n","\n"," IoU threshold = 50 %, used Area-Under-Curve for each unique Recall \n"," mean average precision (mAP@0.50) = 0.999433, or 99.94 % \n","Total Detection Time: 9 Seconds\n","\n","Set -points flag:\n"," `-points 101` for MS COCO \n"," `-points 11` for PascalVOC 2007 (uncomment `difficult` in voc.data) \n"," `-points 0` (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset\n"]}]},{"cell_type":"code","source":["!/content/darknet/darknet detector map /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/obj.data /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/yolov4-tiny.cfg \"/content/drive/MyDrive/cbe_paper/backup/yolov4-tiny_10000.weights\" -points 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2RhMUeiUoBAc","executionInfo":{"status":"ok","timestamp":1654864755401,"user_tz":-540,"elapsed":9924,"user":{"displayName":"한동환","userId":"11772705162839800097"}},"outputId":"2bc445d2-2c65-4bad-87da-be7cb4660e4d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" CUDA-version: 11010 (11020), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n"," CUDNN_HALF=1 \n"," OpenCV version: 3.2.0\n"," 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n","net.optimized_memory = 0 \n","mini_batch = 1, batch = 4, time_steps = 1, train = 0 \n","   layer   filters  size/strd(dil)      input                output\n","   0 Create CUDA-stream - 0 \n"," Create cudnn-handle 0 \n","conv     32       3 x 3/ 2    416 x 416 x   3 ->  208 x 208 x  32 0.075 BF\n","   1 conv     64       3 x 3/ 2    208 x 208 x  32 ->  104 x 104 x  64 0.399 BF\n","   2 conv     64       3 x 3/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.797 BF\n","   3 route  2 \t\t                       1/2 ->  104 x 104 x  32 \n","   4 conv     32       3 x 3/ 1    104 x 104 x  32 ->  104 x 104 x  32 0.199 BF\n","   5 conv     32       3 x 3/ 1    104 x 104 x  32 ->  104 x 104 x  32 0.199 BF\n","   6 route  5 4 \t                           ->  104 x 104 x  64 \n","   7 conv     64       1 x 1/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.089 BF\n","   8 route  2 7 \t                           ->  104 x 104 x 128 \n","   9 max                2x 2/ 2    104 x 104 x 128 ->   52 x  52 x 128 0.001 BF\n","  10 conv    128       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.797 BF\n","  11 route  10 \t\t                       1/2 ->   52 x  52 x  64 \n","  12 conv     64       3 x 3/ 1     52 x  52 x  64 ->   52 x  52 x  64 0.199 BF\n","  13 conv     64       3 x 3/ 1     52 x  52 x  64 ->   52 x  52 x  64 0.199 BF\n","  14 route  13 12 \t                           ->   52 x  52 x 128 \n","  15 conv    128       1 x 1/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.089 BF\n","  16 route  10 15 \t                           ->   52 x  52 x 256 \n","  17 max                2x 2/ 2     52 x  52 x 256 ->   26 x  26 x 256 0.001 BF\n","  18 conv    256       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.797 BF\n","  19 route  18 \t\t                       1/2 ->   26 x  26 x 128 \n","  20 conv    128       3 x 3/ 1     26 x  26 x 128 ->   26 x  26 x 128 0.199 BF\n","  21 conv    128       3 x 3/ 1     26 x  26 x 128 ->   26 x  26 x 128 0.199 BF\n","  22 route  21 20 \t                           ->   26 x  26 x 256 \n","  23 conv    256       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.089 BF\n","  24 route  18 23 \t                           ->   26 x  26 x 512 \n","  25 max                2x 2/ 2     26 x  26 x 512 ->   13 x  13 x 512 0.000 BF\n","  26 conv    512       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x 512 0.797 BF\n","  27 conv    256       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x 256 0.044 BF\n","  28 conv    512       3 x 3/ 1     13 x  13 x 256 ->   13 x  13 x 512 0.399 BF\n","  29 conv     24       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x  24 0.004 BF\n","  30 yolo\n","[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.05\n","nms_kind: greedynms (1), beta = 0.600000 \n","  31 route  27 \t\t                           ->   13 x  13 x 256 \n","  32 conv    128       1 x 1/ 1     13 x  13 x 256 ->   13 x  13 x 128 0.011 BF\n","  33 upsample                 2x    13 x  13 x 128 ->   26 x  26 x 128\n","  34 route  33 23 \t                           ->   26 x  26 x 384 \n","  35 conv    256       3 x 3/ 1     26 x  26 x 384 ->   26 x  26 x 256 1.196 BF\n","  36 conv     24       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x  24 0.008 BF\n","  37 yolo\n","[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.05\n","nms_kind: greedynms (1), beta = 0.600000 \n","Total BFLOPS 6.790 \n","avg_outputs = 299930 \n"," Allocate additional workspace_size = 26.22 MB \n","Loading weights from /content/drive/MyDrive/cbe_paper/backup/yolov4-tiny_10000.weights...\n"," seen 64, trained: 640 K-images (10 Kilo-batches_64) \n","Done! Loaded 38 layers from weights-file \n","\n"," calculation mAP (mean average precision)...\n"," Detection layer: 30 - type = 28 \n"," Detection layer: 37 - type = 28 \n","500\n"," detections_count = 2176, unique_truth_count = 1758  \n","class_id = 0, name = marangoni cell, ap = 99.83%   \t (TP = 1628, FP = 28) \n","class_id = 1, name = scale bar, ap = 100.00%   \t (TP = 57, FP = 0) \n","class_id = 2, name = information, ap = 100.00%   \t (TP = 57, FP = 0) \n","\n"," for conf_thresh = 0.25, precision = 0.98, recall = 0.99, F1-score = 0.99 \n"," for conf_thresh = 0.25, TP = 1742, FP = 28, FN = 16, average IoU = 91.33 % \n","\n"," IoU threshold = 50 %, used Area-Under-Curve for each unique Recall \n"," mean average precision (mAP@0.50) = 0.999432, or 99.94 % \n","Total Detection Time: 8 Seconds\n","\n","Set -points flag:\n"," `-points 101` for MS COCO \n"," `-points 11` for PascalVOC 2007 (uncomment `difficult` in voc.data) \n"," `-points 0` (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset\n"]}]},{"cell_type":"markdown","source":["### 5. Prediction\n","\n","전체적인 인식율 이외로, 직접 이미지 상에서 어떻게 인식하는지 보고 싶다면 아래와 같이 weight 파일을 지정하고 어느 이미지를 인식할지 이미지 경로를 입력해주면 결과를 확인할 수 있다. darknet 폴더 안에 들어가면 prediction.jpg로 알고리즘이 이미지 내에서 예측한 결과를 확인할 수 있다."],"metadata":{"id":"IrGBxywEv-VO"}},{"cell_type":"code","source":["!/content/darknet/darknet detector test /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/obj.data  /content/drive/MyDrive/cbe_paper/yolotinyv3_medmask_demo/yolov4-tiny.cfg  \"/content/drive/MyDrive/cbe_paper/backup/yolov4-tiny_best.weights\" /content/drive/MyDrive/cbe_paper/test_rod_particle_marangoni_bbx/Rod_particle_marangoni_00_00_07_02_218.jpg -ext_output -threshold 50"],"metadata":{"id":"MbilIk29wEbK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655049123495,"user_tz":-540,"elapsed":2559,"user":{"displayName":"한동환","userId":"11772705162839800097"}},"outputId":"33a299cb-8a0c-4be7-c498-3f78c44eb70d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" CUDA-version: 11010 (11020), cuDNN: 7.6.5, CUDNN_HALF=1, GPU count: 1  \n"," CUDNN_HALF=1 \n"," OpenCV version: 3.2.0\n"," 0 : compute_capability = 750, cudnn_half = 1, GPU: Tesla T4 \n","net.optimized_memory = 0 \n","mini_batch = 1, batch = 4, time_steps = 1, train = 0 \n","   layer   filters  size/strd(dil)      input                output\n","   0 Create CUDA-stream - 0 \n"," Create cudnn-handle 0 \n","conv     32       3 x 3/ 2    416 x 416 x   3 ->  208 x 208 x  32 0.075 BF\n","   1 conv     64       3 x 3/ 2    208 x 208 x  32 ->  104 x 104 x  64 0.399 BF\n","   2 conv     64       3 x 3/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.797 BF\n","   3 route  2 \t\t                       1/2 ->  104 x 104 x  32 \n","   4 conv     32       3 x 3/ 1    104 x 104 x  32 ->  104 x 104 x  32 0.199 BF\n","   5 conv     32       3 x 3/ 1    104 x 104 x  32 ->  104 x 104 x  32 0.199 BF\n","   6 route  5 4 \t                           ->  104 x 104 x  64 \n","   7 conv     64       1 x 1/ 1    104 x 104 x  64 ->  104 x 104 x  64 0.089 BF\n","   8 route  2 7 \t                           ->  104 x 104 x 128 \n","   9 max                2x 2/ 2    104 x 104 x 128 ->   52 x  52 x 128 0.001 BF\n","  10 conv    128       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.797 BF\n","  11 route  10 \t\t                       1/2 ->   52 x  52 x  64 \n","  12 conv     64       3 x 3/ 1     52 x  52 x  64 ->   52 x  52 x  64 0.199 BF\n","  13 conv     64       3 x 3/ 1     52 x  52 x  64 ->   52 x  52 x  64 0.199 BF\n","  14 route  13 12 \t                           ->   52 x  52 x 128 \n","  15 conv    128       1 x 1/ 1     52 x  52 x 128 ->   52 x  52 x 128 0.089 BF\n","  16 route  10 15 \t                           ->   52 x  52 x 256 \n","  17 max                2x 2/ 2     52 x  52 x 256 ->   26 x  26 x 256 0.001 BF\n","  18 conv    256       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.797 BF\n","  19 route  18 \t\t                       1/2 ->   26 x  26 x 128 \n","  20 conv    128       3 x 3/ 1     26 x  26 x 128 ->   26 x  26 x 128 0.199 BF\n","  21 conv    128       3 x 3/ 1     26 x  26 x 128 ->   26 x  26 x 128 0.199 BF\n","  22 route  21 20 \t                           ->   26 x  26 x 256 \n","  23 conv    256       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x 256 0.089 BF\n","  24 route  18 23 \t                           ->   26 x  26 x 512 \n","  25 max                2x 2/ 2     26 x  26 x 512 ->   13 x  13 x 512 0.000 BF\n","  26 conv    512       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x 512 0.797 BF\n","  27 conv    256       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x 256 0.044 BF\n","  28 conv    512       3 x 3/ 1     13 x  13 x 256 ->   13 x  13 x 512 0.399 BF\n","  29 conv     24       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x  24 0.004 BF\n","  30 yolo\n","[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.05\n","nms_kind: greedynms (1), beta = 0.600000 \n","  31 route  27 \t\t                           ->   13 x  13 x 256 \n","  32 conv    128       1 x 1/ 1     13 x  13 x 256 ->   13 x  13 x 128 0.011 BF\n","  33 upsample                 2x    13 x  13 x 128 ->   26 x  26 x 128\n","  34 route  33 23 \t                           ->   26 x  26 x 384 \n","  35 conv    256       3 x 3/ 1     26 x  26 x 384 ->   26 x  26 x 256 1.196 BF\n","  36 conv     24       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x  24 0.008 BF\n","  37 yolo\n","[yolo] params: iou loss: ciou (4), iou_norm: 0.07, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.05\n","nms_kind: greedynms (1), beta = 0.600000 \n","Total BFLOPS 6.790 \n","avg_outputs = 299930 \n"," Allocate additional workspace_size = 26.22 MB \n","Loading weights from /content/drive/MyDrive/cbe_paper/backup/yolov4-tiny_best.weights...\n"," seen 64, trained: 543 K-images (8 Kilo-batches_64) \n","Done! Loaded 38 layers from weights-file \n"," Detection layer: 30 - type = 28 \n"," Detection layer: 37 - type = 28 \n","/content/drive/MyDrive/cbe_paper/test_rod_particle_marangoni_bbx/Rod_particle_marangoni_00_00_07_02_218.jpg: Predicted in 5.008000 milli-seconds.\n","marangoni cell: 85%\t(left_x:  190   top_y:  412   width:  113   height:  121)\n","marangoni cell: 88%\t(left_x:  289   top_y:  318   width:  117   height:  121)\n","marangoni cell: 84%\t(left_x:  519   top_y:  367   width:  124   height:   97)\n","scale bar: 100%\t(left_x:  738   top_y:  677   width:  249   height:   40)\n","information: 97%\t(left_x:  747   top_y:  640   width:  192   height:   52)\n","Unable to init server: Could not connect: Connection refused\n","\n","(predictions:1322): Gtk-\u001b[1;33mWARNING\u001b[0m **: \u001b[34m15:52:03.002\u001b[0m: cannot open display: \n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["pD4wp5O1b8KL","ons905c_yT6a","BII39NEcnAAX","fzSlopoJp-5l","IrGBxywEv-VO"],"name":"marangoni_cell_images_analysis.ipynb","provenance":[{"file_id":"1tedyOtn8LwHy7eggetN0Y1vy6wXwLTpJ","timestamp":1646459362009}],"mount_file_id":"1qjpb4peJabL0w7GZjy5-QQpXOzUVxoYh","authorship_tag":"ABX9TyMULncJsPI2s78I9jR+wdBv"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}